#! /usr/bin/env ruby

require 'tempfile'
require 'open3'
require 'docopt'
require 'ostruct'
require 'json'

HOME_DIR = File.expand_path( "#{File.dirname __FILE__}/.." )

class Mule
  class TerraformState
    PROGRAM = {
      :cluster_name  => { :tfvars  => true },
      :domain_name   => { :tfvars  => true },
      :bastion_key   => { :tfvars  => true },
      :cluster_key   => { :tfvars  => true },
      :region_name   => { :tfvars  => true },
      :zone_name     => { :tfvars  => true },
      :vpc_name      => { :address => 'module.vpc.ibm_is_vpc.vpc', :filter => 'name', :line => 1 },
      :bastion_fip   => { :address => 'module.vpc.ibm_is_floating_ip.bastion_server_fip[0]', :filter => 'address' },
      :installer_pip => { :address => 'ibm_is_instance.installer', :filter => 'primary_ipv4_address' },
      :lb_pip        => { :address => 'ibm_is_instance.load_balancer', :filter => 'primary_ipv4_address' },
      :bootstrap_pip => { :address => 'ibm_is_instance.bootstrap', :filter => 'primary_ipv4_address' },
      :master_1_pip  => { :address => 'ibm_is_instance.master[0]', :filter => 'primary_ipv4_address' },
      :master_2_pip  => { :address => 'ibm_is_instance.master[1]', :filter => 'primary_ipv4_address' },
      :master_3_pip  => { :address => 'ibm_is_instance.master[2]', :filter => 'primary_ipv4_address' },
      :worker_1_pip  => { :address => 'ibm_is_instance.worker[0]', :filter => 'primary_ipv4_address' },
      :worker_2_pip  => { :address => 'ibm_is_instance.worker[1]', :filter => 'primary_ipv4_address' },
      :bastion_id    => { :sh => "ibmcloud is ins | awk '{if($2==\"bastion\" && $8==\"\#{self.vpc_name}\" && $9==\"\#{self.zone_name}\") print $1}'" },
      :installer_id  => { :address => 'ibm_is_instance.installer', :filter => 'id' },
      :lb_id         => { :address => 'ibm_is_instance.load_balancer', :filter => 'id' },
      :bootstrap_id  => { :address => 'ibm_is_instance.bootstrap', :filter => 'id' },
      :master_1_id   => { :address => 'ibm_is_instance.master[0]', :filter => 'id' },
      :master_2_id   => { :address => 'ibm_is_instance.master[1]', :filter => 'id' },
      :master_3_id   => { :address => 'ibm_is_instance.master[2]', :filter => 'id' },
      :worker_1_id   => { :address => 'ibm_is_instance.worker[0]', :filter => 'id' },
      :worker_2_id   => { :address => 'ibm_is_instance.worker[1]', :filter => 'id' }
    }

    def initialize( state_file, tfvars_file )
      @state_file   = state_file
      @tfvars_files = tfvars_file
      @cache        = {}
    end

    def method_missing( m, *args, &block )
      if @cache.include? m
        @cache[ m ]

      elsif PROGRAM.include? m
        if PROGRAM[ m ].include? :tfvars
          @cache[ m ] = %x[ cat #{@tfvars_files} | awk -F '"' '/#{m.to_s}.*=/{print $2}' ].chomp

        elsif PROGRAM[ m ].include? :address
          address = PROGRAM[ m ][ :address ]
          filter  = PROGRAM[ m ][ :filter ]
          line    = PROGRAM[ m ][ :line ] != nil ? PROGRAM[ m ][ :line ] : 1
          @cache[ m ] = %x[ terraform state show -state=#{@state_file} #{address} | awk -F '"' '/#{filter}.*=/{print $2}' | head -#{line} | tail -1 ].chomp

        elsif PROGRAM[ m ].include? :sh
          sh = PROGRAM[ m ][ :sh ]
          @cache[ m ] = eval "%x[ #{sh} ].chomp"
        else
          puts "Unknown program type for '#{m}'"
          raise
        end
      else
        puts "Element '#{m}' not found"
        raise
      end
    end
  end # class

  class IBMCloudCLI
    def initialize( state )
      ENV[ 'IBMCLOUD_COLOR' ] = 'false'
      @state = state
      login
    end

    def login
      puts "Logging in to IBM Cloud..."
      %x[ ibmcloud login -r #{@state.region_name}
          ibmcloud is target --gen 2 ]
    end

    def is_instance_start( name, id )
      print "Starting instance '#{name}' id=#{id}..."
      rc = %x[ ibmcloud is instance-start #{id} 2>&1 >/dev/null
               echo ${?} ].chomp

      if rc == "0"
        puts " Ok"
      else
        puts " Error, rc=#{rc}"
      end
    end

    def is_instance_stop( name, id )
      print "Stopping instance '#{name}' id=#{id}..."
      rc = %x[ ibmcloud is instance-stop #{id} 2>&1 >/dev/null
               echo ${?} ].chomp

      if rc == "0"
        puts " Ok"
      else
        puts " Error, rc=#{rc}"
      end
    end

  end # class

  class Main
    @@usage = <<~DOC
      NAME:
        mule - Create a simple openshift v4.3 cluster on IBM Cloud

      USAGE:
        mule (provision|destroy)  (--all|--infra|--openshift)
        mule (start|restart|stop) (--all|--infra|--masters|--workers)

      OPTIONS:
        --name=<name>  The name of the newly created resource

      DOC

    def run()
      begin
        options = Docopt::docopt( @@usage )
      rescue Docopt::Exit => e
        puts @@usage
        exit 1
      end

      state = Mule::TerraformState.new "#{HOME_DIR}/terraform.tfstate", "#{HOME_DIR}/*.tfvars"
      cli   = Mule::IBMCloudCLI.new state

      if options[ 'start' ]
        if options[ '--all' ]
          %w[ bastion installer lb bootstrap master_1 master_2 master_3 worker_1 worker_2 ].each do | server |
            id = eval "state.#{server}_id"
            cli.is_instance_start server, id
          end
        end # --all
      end # start
    end # run()
  end # class Main

end # class Mule

Mule::Main.new.run

# ENV[ 'IBMCLOUD_COLOR' ] = 'false'
#
#     HOME_DIR = File.expand_path( "#{File.dirname __FILE__}/.." )
#      RUN_DIR = Dir.pwd
#    STATE_DIR = "#{RUN_DIR}"
# SSH_KEYS_DIR = "#{RUN_DIR}/ssh-keys"
#
# def ibmcloud_cli_init( region )
#   %x[ ibmcloud login -r #{region}
#       ibmcloud is target --gen 2 ]
# end
#
# def terraform_init
#   if !File.exist? '.terraform'
#     %x[ echo 'provider "ibm" {}' > dummy.tf
#         terraform init
#         rm dummy.tf ]
#   end
# end
#
# def terraform( dir, vars = nil )
#   plan_dir  = "#{HOME_DIR}/lib/modules/#{dir}"
#   vars_file = "#{RUN_DIR}/#{dir}.tfvars"
#
#   # write vars
#   if !vars.nil?
#     puts "Writing #{vars_file}..."
#     File.open vars_file, 'w' do | f |
#       vars.each do | k, v |
#         if v.is_a? Hash
#           v_s = ""
#           v.each { | k1, v1 | v_s += "#{k1} = \"#{v1}\"\n" }
#           f.write "#{k} = {\n#{v_s}}"
#         else
#           f.write "#{k} = \"#{v}\"\n"
#         end
#       end
#     end
#   end
#
#   var_files_option = ""
#   Dir.glob( "#{RUN_DIR}/*.tfvars" ) do | f |
#     var_files_option += "-var-file=#{File.basename f} "
#   end
#
#   # prepare command
#   puts "Running terraform..."
#   cmd = <<-EOT.gsub( /\s+/, ' ' ).strip
#     terraform apply
#       -auto-approve
#       -state #{STATE_DIR}/#{dir}.tfstate
#       -compact-warnings
#       #{var_files_option}
#       #{plan_dir}
#   EOT
#
#   puts cmd
#
#   # run terraform
#   status = nil
#   Open3.popen2e( cmd ) do | stdin, stdout_err, wait_thread |
#     while line = stdout_err.gets
#       puts line
#     end
#     status = wait_thread.value
#   end
#
#   status.exitstatus
# end # terraform
#
# # ---- MAIN ----
#
# usage = <<~DOC
#   NAME:
#     mule - Create simple openshift v4.3 cluster on IBM Cloud
#
#   USAGE:
#     mule new cluster --name=<name> --location=<loc>... --resource-group=<rg>
#     mule new node    --name=<name> --type=<type>
#     mule rm  node    --name=<name> [--force]
#
#   OPTIONS:
#     --name=<name>           The name of the newly created resource
#     --location=<loc>        The location of the resource, given as region:zone[:subnet]
#     --resource-group=<rg>   The name of the resource group to put the resources in
#     --type=<type>           The type of the node, one of (master|worker)
#   DOC
#
# begin
#   options = Docopt::docopt( usage )
# rescue Docopt::Exit => e
#   puts usage
#   exit 1
# end
#
# if options[ 'new' ]
#
#   # new cluster
#   if options[ 'cluster' ]
#     puts "Creating new cluster..."
#
#     name           = options[ '--name' ]
#     resource_group = options[ '--resource-group' ]
#
#     locations = options[ '--location' ]
#     quit 'Error, only a single location is supported at this time' if locations.size != 1
#     region, zone = locations[ 0 ].split ':'
#
#     Dir.mkdir SSH_KEYS_DIR if !File.exist? SSH_KEYS_DIR
#     admin_private_key = "#{SSH_KEYS_DIR}/#{name}.rsa"
#     admin_public_key  = "#{admin_private_key}.pub"
#
#     if !File.exist? admin_private_key
#       puts "Generating new ssh key..."
#       %x[ ssh-keygen -t rsa -b 4096 -N "" -f #{admin_private_key} ]
#     end
#
#     ibmcloud_cli_init( region )
#     terraform_init()
#
#     # terraform 'vpc-infra', {
#     #   :resource_group_name => resource_group,
#     #   :vpc_name            => name,
#     #   :region_name         => region,
#     #   :zone_name           => zone,
#     #   :admin_public_key    => admin_public_key }
#
#     subnet_1_id = %x[ ibmcloud is subnets | tail -n +3 | awk '{ if ($2 == "subnet-1" && $8 == "#{name}") { print $1} }' ].chomp
#
#     # workaround for https://github.com/IBM-Cloud/terraform-provider-ibm/issues/1292
#     security_groups_map = {}
#     %x[ ibmcloud is sgs | awk '$5 == "#{name}"' | awk '{print $2" "$1}' ].chomp.each_line do | line |
#       name, id = line.split
#       security_groups_map[ name.to_sym ] = id
#     end
#
#     terraform 'installation-server', {
#       :vpc_name            => name,
#       :region_name         => region,
#       :subnet_id           => subnet_1_id,
#       :security_groups_map => security_groups_map }
#
#     terraform 'network-server', {
#       :vpc_name            => name,
#       :region_name         => region,
#       :subnet_id           => subnet_1_id ,
#       :security_groups_map => security_groups_map }
#   end
#
# elsif options[ 'add' ]
#   puts 'Not implemented yet'
#   exit 1
#
# elsif options[ 'rm' ]
#   puts 'Not implemented yet'
#   exit 1
#
# end
#
# exit 0
